\documentclass[11pt, a4paper,oneside,chapterprefix=false]{scrbook}

% setup with overleaf
\usepackage{a4wide}
\usepackage{times}
\usepackage{helvet}   % sets sans serif font

\usepackage{amsmath,amssymb,amsthm}
\usepackage{svg}
\usepackage{graphicx}
\usepackage{subfigure}  
\usepackage{fancybox} % for shadowed or double bordered boxes
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{cite}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{xargs}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}


\newcommand{\todochange}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}

\DeclareGraphicsExtensions{.pdf,.jpg,.png}

%% macros
\input{include/math}
\input{include/codelisting_layout}

\usepackage{color}
\definecolor{RED}{rgb}{1,0,0}
\definecolor{GREEN}{rgb}{0,0.7,0}
\definecolor{BLUE}{rgb}{0,0,1}
\newcommand{\FIXME}[1]{{\color{RED}{\textbf{FIX}: #1}}}

\addtolength{\textheight}{2.0cm}
\addtolength{\voffset}{-1cm}
\addtolength{\textwidth}{1.8cm}
\addtolength{\hoffset}{-.9cm}

\widowpenalty=10000
\clubpenalty=10000

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    stringstyle=\color{string},
    keywordstyle=\color{keyword},
    commentstyle=\color{comment},
    morecomment=[l]{//},
    morecomment=[s]{/*}{*/},
    morecomment=[l]{\#},
    morestring=[b]",
    morestring=[b]',
    morekeywords={true,false,null}
}

\definecolor{background}{HTML}{EEEEEE}
\definecolor{keyword}{RGB}{170,85,0}
\definecolor{string}{RGB}{0,128,0}
\definecolor{comment}{RGB}{128,128,128}

\lstdefinestyle{terminal}{
    backgroundcolor=\color{black},
    basicstyle=\ttfamily\color{white}\small,
    breaklines=true
}

\begin{document}

\frontmatter
%\maketitle %automatic version
% --- selfmade version ----
\begin{titlepage}
	\setlength{\parindent}{0cm}
	\addtolength{\textheight}{1.0cm}

	\vspace{0.2cm}
	\Huge
	\begin{center}
		{\textsf{\textbf{Analyzing the Impact of Occlusion on the Quality of Semantic Segmentation Methods for Point Cloud Data}}}	
	\end{center}
	

	\vfill \vfill \vfill
	\begin{figure}[h]
		\centering
		\includegraphics*[width=0.6\textwidth]{figures/titleimage_yf.png}
	\end{figure}

	\vfill
	\sffamily\Large
	\begin{center}
		{\textbf{Bachelor Thesis}} \\ 
		13th March 2023 - 13th September 2023 \\[0.5cm]
		\large
		Yufeng Xiao \\ 19-763-663
	\end{center}

	\vfill \vfill \vfill
	\begin{minipage}[b]{0.5\textwidth} \raggedright
	Supervisors: \\
	Prof. Dr. Renato Pajarola \\
	Lizeth Joseline Fuentes Perez \\
	\end{minipage}
	%
	\begin{minipage}[b]{0.5\textwidth} \raggedleft
	Visualization and MultiMedia Lab \\
	Department of Informatics \\
	University of Z{\"u}rich
	\end{minipage}

	\vfill
	\hrule
	\vspace{0.5cm}
	\includegraphics*[width=0.3\textwidth]{figures/uzh_logo} \hfill
	\includegraphics*[width=0.3\textwidth]{figures/vmml_logo}
\end{titlepage}
%%

%=====================================================================
\chapter{Abstract} \label{chp:abstract}
%=====================================================================

The abstract heading is similar to any main section heading but without numbering and is similar to the main body text format. Avoid referencing any bibliography in the abstract text.

A clear organization of a report typically encloses the inner main technical part(s) by an introduction and related work section at the beginning, as well as a discussion and/or conclusion section at the end. The inner technical parts must include the precise problem statement(s), a detailed description of the technical solution (e.g. mathematical models, data structures and algorithms), implementation details if applicable, and experimental results.


\tableofcontents

\mainmatter

%=====================================================================
\chapter{Introduction and related works} \label{chp:introduction}
%=====================================================================
\todo{Describe the input point cloud characteristics and the expected output (oclussion metric)}
\todo{ii) Why is this metric important}
\todo{ applications where occlusion can be potentially used (semantic segmentation)}

\section{Previous work}
To the best of our knowledge there is not explicit works that compute oclusion level for an entire scene.
Some related works are as follows:
\todo{ briefly mention related works that use oclusion}

\subsection{Scene Flow Estimation on 3D Point Clouds}
\todo{ summarize the occlusion part in this papers}
Occlusion Guided Scene Flow Estimation on 3D Point Clouds
OcCo: Unsupervised Point Cloud Pre-training via Occlusion Completion

\section{Positioning and contributions}
\todo{Solution: Our insights and technical contributions are:}


The introduction is a crucial part of your report and sets the stage as well as motivates the work you have completed. It briefly introduces the problem, emphasizes its importance and shows to the reader what you did in your work. That is, you show the reader that your problem is fundamental and that it needs to be solved as it fills a gap in the known literature and prior work.

The introduction sets the stage and it motivates why the work presented is of any interest, it introduces the problem and emphasizes its importance. It makes the reviewer interested and strategizes the presentation -- arguments that lead to the conclusion that the considered problem is important. A practical problem motivates the work and hints at the gaps in the known literature.

Note that the introduction must briefly but clearly state the open problems, goals, or design criteria that previous work did not yet completely solve. However, in the introduction this is done without going into details as the related work section will follow up on this in more detail.

The introduction starts by addressing the problem in general and points the reader in the direction how you want to solve your problem / research question. As a metaphor, John Swales developed a three-stage model for research introductions: 

\begin{description}
\item[Move 1:] Establish a territory (claim centrality of topic)
\item[Move 2:] Establish a niche (indicate gap)
\item[move 3:] Occupy the niche (outline purpose and indicate research structure/methods).
\end{description}

You may follow that model while writing the introduction. In the first part of the introduction or in a separate section, you are expected to mention and organize supporting literature where you outline the \emph{state of the art} of your research question.

At the end of the introduction you may include a short summary of the structure of the rest of the paper, but this can be omitted for saving space (and avoiding the obvious). The introduction together with the conclusion should give a complete short version of your work and what you have achieved.

%=====================================================================
\section{Technical background}
%=====================================================================
\subsection{Point Cloud Data}

A point cloud is a collection of data points situated in a three-dimensional coordinate system. Each point in this system is represented by a set of three numbers, denoting its position in space. This representation is fundamental for capturing the intricate details of 3D environments, be it the bustling streets of a city or the serene interiors of a room. Point clouds are often derived from 3D sensors or scanning mechanisms, and their rich information content makes them the primary input format for semantic segmentation tasks.

Given the complexity of point cloud data and the challenges posed by occlusions, the Minkowski Engine's focus on sparse tensors offers a promising avenue for advancing the state of the art in semantic segmentation. By leveraging its capabilities, researchers and practitioners can hope to achieve more accurate and robust segmentation results, even in challenging environments.

\subsection{Semantic Segmentation}
Semantic segmentation for point cloud data has rapidly ascended as a pivotal research domain, given its profound implications in a myriad of applications. From the intricate pathways navigated by autonomous vehicles to the precise movements of robotics and the detailed analysis of 3D scenes, the ability to accurately segment and categorize each data point in a 3D environment is paramount.

At the heart of this research lies the challenge of dealing with occlusions. In real-world scenarios, objects within a scene often overlap or obstruct each other, leading to partial or even complete occlusions. Such occlusions can significantly distort the spatial distribution of data points, making it challenging to discern the true structure and category of the obstructed objects. For instance, in an urban driving scenario, a pedestrian might be partially hidden behind a parked car, or in an indoor setting, a chair might be obscured by a table. These occlusions can lead to misclassifications, reducing the overall accuracy of the segmentation process.

This project proposal is rooted in the quest to unravel the intricacies of occlusion within point cloud data. Specifically, we aim to delve deep into understanding how varying levels of occlusion in a scene impact the performance and quality of semantic segmentation methods. By systematically analyzing the effects of occlusion, we aspire to shed light on potential strategies to enhance segmentation accuracy, even in highly occluded environments.

Through this investigation, we hope to not only advance the state of the art in point cloud data segmentation but also pave the way for more robust applications in autonomous driving, robotics, and 3D scene analysis.

\subsubsection{Minkowski Engine}

The Minkowski Engine stands out as a state-of-the-art tool in this domain. It is an auto-differentiation library specifically designed for sparse tensors. In the realm of deep learning, where dense tensors are commonly used, the Minkowski Engine brings a fresh perspective by focusing on sparse tensors. This is particularly beneficial for 3D data, which often exhibits spatial sparsity. The engine supports all standard neural network layers, including convolution, pooling, unpooling, and broadcasting operations, but tailored for sparse tensors. Such capabilities make it an ideal choice for semantic segmentation tasks, especially when dealing with point cloud data.

\begin{figure}[h]
    \centering
    \includegraphics*[width=0.6\textwidth]{figures/Minkowski Engine.png}
    \caption{Minkowski Engine Indoor Scene Segmentation}
    \label{fig:minkowski}
\end{figure}



\section{Motivation} \label{sec:motivation}

Among the myriad factors influencing the semantic segmentation of point cloud data, the level of occlusion stands as a paramount challenge. Occlusions, a prevalent phenomenon in 3D scenes, can significantly compromise the quality and integrity of data. When objects are partially or entirely obscured by others, conventional semantic segmentation approaches might falter, leading to inaccuracies in segmentation. While the issue of occlusion has garnered attention in 3D data processing, current research on how different occlusion levels impact the quality of semantic segmentation remains fragmented. Specifically, there's a palpable gap in understanding how to quantify occlusion levels and how these levels influence the performance of advanced tools like the Minkowski Engine. 

Thus, the primary motivation behind this research is to systematically evaluate occlusion levels and delve deep into their implications on point cloud data semantic segmentation. Through this investigation, we aim to offer more precise semantic segmentation methodologies, especially in environments with high levels of occlusion. In essence, our objective is to forge a nexus between occlusion levels and the efficacy of semantic segmentation, providing invaluable insights for future research and applications.

\section{Outline} \label{sec:outline}

In this work we use ray-tracing based methods to scan ground truth cloud and compute occlusion level for the scanned cloud. Before we doing this, we aplly similar methods to estimate occlusion level of mesh to validate that ray-based methods are reliable.

Finally, an interactive web application is developed to visualize the point cloud together with a backend is developed to compute the occlusion level of the point cloud.


%=====================================================================
\chapter{Problem Statement} \label{chp:problem}
%=====================================================================



\section{Occlusion Level Computation of Mesh} \label{sec:occlusion}

We have to validate here that more viewpoints lead to lower occlusion level of the interior scene.

\subsection{Ground Truth Mesh} \label{subsec:occlusion}

We should compute the occlusion level of ground truth mesh.

\subsection{Estimated Mesh from Point Cloud} \label{subsec:occlusion}

We also want to estimate the occlusion level of the mesh generated from ground truth point cloud.
\todo{Why do we wanna do this?}

\section{Occlusion Level Computation of Point Cloud} \label{sec:occlusion}

After validation in previous steps, we should directly compute the occlusion level of the ground truth point cloud.

\section{Evaluation of Segmentation Result} \label{sec:evaluation}

It's essential to evaluate result of segmentation of point cloud so that we can maybe find correlation between occlusion level and segmentation performance.

%=====================================================================
\chapter{Technical Solution} \label{chp:solution}
%=====================================================================

In this chapter we will introduce our technical solution to the problem stated in \ref{chp:problem}.

\section{Ray Tracing Based Estimation of Visible Area Ratio} \label{sec:ray tracing visible area ratio}

Ray tracing is a powerful technique used in computer graphics to simulate the way light interacts with objects to generate realistic images. In the context of our study, ray tracing plays a pivotal role in estimating the visible area ratio of triangles in a scene. This estimation is crucial for understanding how much of a triangle's surface is directly illuminated by a light source, especially when other objects in the scene might occlude it.

A flow chart of the whole pipeline is shown here.

\begin{minipage}{\textwidth}
	\begin{figure}[H]
		\centering
		\includegraphics*[width=1.0\textwidth]{figures/visible area.png}
		\caption{Flow chart of visible area ratio estimation}
		\label{fig:visible area ratio estimation}
	\end{figure}
\end{minipage}

\subsection{Uniform Sample Triangles}

To accurately represent a triangle's area using samplings, it's imperative that these samplings comprehensively cover the triangle. For this purpose, we employ the random uniform sampling method. This method ensures that each point within the triangle has an equal chance of being selected, leading to a fair representation of the triangle's entire area.

The process begins by randomly generating two parameters, \( r_1 \) and \( r_2 \), both of which lie in the interval [0, 1]. These random parameters are then used to compute the barycentric coordinates of the sampled points within the triangle. The barycentric coordinates, denoted as \( \alpha \), \( \beta \), and \( \gamma \), allow us to express any point within the triangle as a linear combination of the triangle's vertices.

To derive the sampled point's coordinates using \( r_1 \) and \( r_2 \), we use the following equations:
\[ \alpha = 1 - \sqrt{r_1} \]
\[ \beta = \sqrt{r_1} \times r_2 \]
\[ \gamma = 1 - \alpha - \beta \]
\[ P = \alpha V_1 + \beta V_2 + \gamma V_3 \]

Where \( P \) is the sampled point, and \( V_1 \), \( V_2 \), and \( V_3 \) are the triangle's vertices. Below is a visualization of the uniform sampling method.

\begin{minipage}{\textwidth}
	\begin{figure}[H]
		\centering
		\includegraphics*[width=0.6\textwidth]{figures/uniform sample triangle.png}
		\caption{Uniform Sample Triangle}
		\label{fig:uniform sample triangle}
	\end{figure}
\end{minipage}

\subsection{Generate Rays}

In computer graphics, especially in the context of ray tracing, generating rays is a fundamental step. These rays simulate the path of light as it interacts with objects in a scene. In our approach, we generate rays from the sampled points on the triangle to a light source. This is crucial for determining how light interacts with the triangle, especially when considering factors like shading and occlusion.

The sampled points serve as the origin of each ray, while the view point (or light source) acts as the destination. The direction of each ray is computed based on the difference between the destination and the origin. The direction vector is then normalized to ensure its magnitude is 1, which simplifies subsequent calculations.

The direction of the ray, \( \text{Direction} \), can be computed as:

\begin{equation}
	\text{Direction} = \frac{\text{Destination} - \text{Origin}}{\|\text{Destination} - \text{Origin}\|}
\end{equation}

Where:
\begin{itemize}
    \item \(\text{Origin}\) is the starting point of the ray, which in our case is the sampled point on the triangle.
    \item \(\text{Destination}\) is the end point of the ray, typically representing the viewpoint or light source.
\end{itemize}

By generating rays in this manner, we can accurately simulate the behavior of light as it travels from the triangle to the viewpoint or light source. This is essential for producing realistic renderings and for analyzing the effects of various factors, such as occlusion, on the final image.


\subsection{Ray Triangle Intersection}

Ray-triangle intersection is a fundamental operation in computer graphics, especially in the context of ray tracing. Determining whether a ray intersects a triangle and finding the intersection point are crucial for rendering scenes composed of triangular meshes.

One of the most efficient and widely used algorithms for this purpose is the Möller–Trumbore intersection algorithm. This algorithm determines the intersection of a ray and a triangle in a 3D space without any need for pre-computed plane equations.

Given a ray represented by its origin \( O \) and direction \( D \), and a triangle defined by its vertices \( V_1 \), \( V_2 \), and \( V_3 \), the algorithm computes the intersection using barycentric coordinates.

The intersection point \( P \) can be represented as:
\[ P = (1 - u - v) V_1 + u V_2 + v V_3 \]

Where \( u \) and \( v \) are the barycentric coordinates. The ray intersects the triangle if \( 0 \leq u \leq 1 \), \( 0 \leq v \leq 1 \), and \( u + v \leq 1 \).

The algorithm uses the following equations to compute \( u \), \( v \), and \( t \) (where \( t \) is the distance from the ray origin to the intersection point):

\begin{itemize}
    \item \textbf{Edge Vectors:} These vectors represent two edges of the triangle.
	\[ e_1 = V_2 - V_1 \]
	\[ e_2 = V_3 - V_1 \]
	
    \item \textbf{Vector \( h \):} The cross product of the ray direction and \( e_2 \).
    \[ h = D \times e_2 \]
    
    \item \textbf{Determinant \( a \):} It's used to check if the ray is nearly parallel to the triangle.
    \[ a = e_1 \cdot h \]
    
    \item \textbf{Factor \( f \):} Used for subsequent calculations.
    \[ f = \frac{1}{a} \]
    
    \item \textbf{Vector \( s \):} Represents the vector from the ray's origin to one vertex of the triangle.
    \[ s = O - V_1 \]
    
    \item \textbf{Barycentric Coordinate \( u \):} The first computed barycentric coordinate.
    \[ u = f (s \cdot h) \]
    
    \item \textbf{Vector \( q \):} The cross product of vector \( s \) and \( e_1 \).
    \[ q = s \times e_1 \]
    
    \item \textbf{Barycentric Coordinate \( v \):} The second computed barycentric coordinate.
    \[ v = f (D \cdot q) \]
    
    \item \textbf{Distance \( t \) to Intersection:} Represents the distance from the ray's origin to the intersection point.
    \[ t = f (e_2 \cdot q) \]
\end{itemize}

The algorithm first checks if \( a \) is close to zero, which means the ray is nearly parallel to the triangle and thus, likely does not intersect it. If \( a \) is not close to zero, the algorithm proceeds to compute \( u \), \( v \), and \( t \) to determine the intersection.

This algorithm is both efficient and robust, making it a popular choice for ray-triangle intersection tests in various graphics applications.

\subsection{Visible Area Ratio}

In the context of ray tracing and light interaction, understanding the visible area of a triangle is crucial. The visible area ratio provides insight into how much of a triangle's surface is directly illuminated by a light source without being occluded by other objects in the scene.

From the previous steps, we have computed samplings on each triangle and generated rays originating from these samplings directed towards the light source. To determine the visible area, we first need to compute the visibility weight for each sampling. This weight represents the ratio of visible samplings to the total number of samplings on the triangle.

Mathematically, the visibility weight, \( w \), can be defined as:
\begin{equation}
    w = \frac{\text{Number of visible samplings}}{\text{Total number of samplings}}
\end{equation}

The visible area \( A_{\text{visible}} \) of the triangle can then be computed as:
\begin{equation}
    A_{\text{visible}} = w \times A_{\text{total}}
\end{equation}
where \( A_{\text{total}} \) is the total area of the triangle.

A sampling is deemed visible if at least one ray originating from it does not intersect any triangle other than the one from which the sampling was generated. To ascertain this, we must examine all intersections related to the ray emanating from the sampling. If no intersection is closer to the sampling than the distance between the sampling and the light source, then the sampling is considered visible.

This method ensures a precise computation of the visible area, accounting for occlusions and the intricate play of light within the scene.
 
\section{Region Growing Based Estimation of Mesh} \label{sec:region growing mesh estimation}



\subsection{Point Cloud Segmentation}

In our approach, we utilize the region growing algorithm for segmentation. This algorithm works by iteratively expanding a region by adding neighboring points that are similar based on certain criteria, such as geometric proximity and surface normals. Starting from a seed point, the region grows by incorporating neighboring points that meet the similarity criteria until no more points can be added.

The region growing algorithm can be summarized in the following steps:
\begin{enumerate}
    \item Select a seed point from the point cloud that has not been assigned to any cluster.
    \item Identify neighboring points of the seed based on a predefined distance threshold.
    \item Evaluate the similarity of neighboring points based on criteria like curvature or surface normals.
    \item Add the similar neighbors to the current region and mark them as visited.
    \item Repeat the process for the newly added points.
    \item Continue the growth until no more points can be added to the current region.
    \item Start a new region with another unvisited seed point and repeat the process until all points are assigned to clusters.
\end{enumerate}

By the end of this process, we obtain a number of clusters that represent distinct structures or objects in the original point cloud. These segmented clusters facilitate further analysis, such as object recognition, surface reconstruction, and other advanced 3D processing tasks.


\subsection{Build Triangles From Clusters}

After segmenting the point cloud into clusters using the region growing algorithm, the next step is to construct a mesh from these clusters. This mesh representation is essential for applying ray tracing techniques, as described in Section \ref{sec:ray tracing visible area ratio}. To achieve this, we need to build triangles from the clusters.

\subsubsection{Convex Hull Estimate Polygons}

The first step in this process is to compute the convex hull for each cluster. The convex hull can be thought of as the "tightest" polygon that encloses all the points in a cluster. It provides a simplified representation of the cluster's shape, eliminating any concavities. Various algorithms, such as the Graham's scan or the QuickHull algorithm, can be employed to compute the convex hull efficiently.

\subsubsection{Compute Polygon Centroid}

Once the convex hull is determined, the next step is to compute the centroid of each polygon. The centroid, often referred to as the "center of mass" or "balance point", represents the average position of all the points in the polygon. Mathematically, for a simple polygon with vertices \( (x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n) \), the centroid \( (C_x, C_y) \) is given by:
\begin{align*}
C_x &= \frac{1}{n} \sum_{i=1}^{n} x_i \\
C_y &= \frac{1}{n} \sum_{i=1}^{n} y_i
\end{align*}
With the centroid computed, we then connect the centroid to each of the vertices of the polygon. This results in a series of triangles that fan out from the centroid, providing a triangulated representation of the cluster.

\subsubsection{Occlusion Level Estimation}

With the triangles constructed, we can now estimate the occlusion level of the mesh. By applying the ray tracing method described in Section \ref{sec:ray tracing visible area ratio}, we can determine how much of each triangle is visible from a given viewpoint. This information is invaluable for various applications, including rendering, simulation, and analysis, as it provides insights into the visibility and shading characteristics of the mesh in a scene.


\section{Ray Tracing Based Point Cloud Scanning} \label{sec:ray tracing point cloud scanning}

Ray tracing is a powerful technique that simulates the path of rays as they traverse through a scene. In the context of point cloud data, ray tracing can be employed to identify visible and occluded regions within the cloud. By scanning the ground truth point cloud using a ray tracing based method, we can derive a modified point cloud where the retained points represent the visible areas, while the removed points indicate occluded regions.

\subsection{Spherical Light Source}

To simulate a light source that emits rays in all directions, we use a spherical model. Points are uniformly sampled on the surface of this sphere, with each point representing a potential origin for a ray. The number of rays (or sampled points) is predetermined and can be adjusted based on the desired resolution or accuracy of the scan.

\subsection{Ray Point Intersection}

In our model, each point within the point cloud is represented as a small sphere with a defined radius. This simplifies the ray-point intersection check, as we can treat each point as a volumetric entity rather than a singular coordinate in space.

\subsection{Ray Tracing Based Occlusion Computation}

To determine occlusion within the point cloud, rays are generated from multiple points on the spherical light source. The occlusion level for each point in the cloud is computed based on the number of rays that do not intersect any point in the cloud or any openings in the scene.

In this context, we introduce the concept of "occlusion rays". These are rays that, after being cast from the light source, do not intersect with any point in the point cloud or any defined openings in the scene.

\subsubsection{Ray Point Cloud Intersection}

For a ray to be classified as an occlusion ray, it must first be determined that it does not intersect with any point in the point cloud. If an intersection is detected, the ray is immediately disqualified from being an occlusion ray.

\subsubsection{Ray Openings Intersection}

Openings or gaps in the scene, such as windows or doorways, should not contribute to occlusion. Therefore, if a ray does not intersect with the point cloud but does intersect with an opening, it is also not considered an occlusion ray. Only when a ray satisfies both these conditions – not intersecting with the point cloud and not intersecting with any openings – is it classified as an occlusion ray.

To quantify the occlusion within the point cloud, we compute the ratio of occlusion rays to the total number of rays cast. This "occlusion ray ratio" provides a measure of the occlusion level within the point cloud, with higher ratios indicating greater levels of occlusion.


\section{Evaluate Performance with Metrics}

In the realm of semantic segmentation, evaluating the performance of a model is crucial to ensure its reliability and effectiveness. Metrics serve as standardized measures to assess the quality of segmentation results, comparing the predicted outputs against the ground truth. By using these metrics, researchers and practitioners can gauge the strengths and weaknesses of their models, facilitating improvements and ensuring optimal performance. In this section, we discuss the metrics used to evaluate the performance of semantic segmentation models.

\subsection{Semantic Classes}

Due to the difference of the dataset and the pre-trained model, we consider the following classes in our semantic segmentation task:

\subsection{Metrics}

We use the following metrics to evaluate the performance of our model:

\subsubsection{IoU}

Inttersection over Union, also known as the Jaccard Index, IoU measures the overlap between the predicted segmentation and the ground truth. It's calculated as the area of overlap divided by the area of union of the two sets.

\begin{equation}
	IoU = \frac{\text{Intersection}}{\text{Union}}
\end{equation}

A higher IoU indicates better segmentation accuracy.

\subsubsection{F1 Score}

The F1 Score is the harmonic mean of precision and recall. It provides a balance between the two, ensuring that both false positives and false negatives are taken into account.

\begin{equation}
	F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

An F1 Score closer to 1 indicates better performance, while a score closer to 0 indicates poor performance.

\subsubsection{Accuracy}

Accuracy measures the proportion of correctly predicted segmentation pixels to the total number of pixels.

\begin{equation}
	\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}
\end{equation}

While a useful metric, accuracy can sometimes be misleading, especially if the classes are imbalanced.

\subsubsection{Recall}

Recall measures the proportion of actual positives that were correctly identified.

\begin{equation}
	\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
\end{equation}

A higher recall indicates that fewer actual positives were missed by the model.

\subsubsection{Precision}

Precision measures the proportion of positive identifications that were actually correct.

\begin{equation}
	\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
\end{equation}

A higher precision indicates that a larger percentage of the model's positive predictions were correct.

%=====================================================================
\chapter{Implementation} \label{chp:implementation}
%=====================================================================


\section{PCL Serves as Main Component of Computation} \label{sec:pcl and eigen}

PCL is the main component of our implementation. We use PCL to read point cloud data, segment point cloud, compute occlusion level of point cloud, and visualize point cloud. We also use Eigen to compute some mathematical operations within the whole pipeline.

\subsection{Uniform Sampling} \label{subsec:uniform sampling}

Sampling for sphere and triangle. Standard library is used for generating uniformly distributed random numbers.

\subsubsection{Spherical Light Source}

\subsubsection{Triangle}

\subsection{Mesh Estimation} \label{sec:mesh estimation}

\subsubsection{Region Growing}

\begin{lstlisting}[language=C++, caption=Region Growing]
pcl::search::KdTree<pcl::PointXYZ>::Ptr tree(new pcl::search::KdTree<pcl::PointXYZ>());
pcl::PointCloud<pcl::Normal>::Ptr normals(new pcl::PointCloud<pcl::Normal>);
pcl::NormalEstimation<pcl::PointXYZ, pcl::Normal> normal_estimation;
normal_estimation.setInputCloud(cloud);
normal_estimation.setSearchMethod(tree);
normal_estimation.setKSearch(50);
normal_estimation.compute(*normals);

pcl::RegionGrowing<pcl::PointXYZ, pcl::Normal> reg;
reg.setMinClusterSize(min_cluster_size);
reg.setMaxClusterSize(max_cluster_size);
reg.setSearchMethod(tree);
reg.setNumberOfNeighbours(num_neighbours);
reg.setInputCloud(cloud);
reg.setInputNormals(normals);
reg.setSmoothnessThreshold(smoothness_threshold / 180.0 * M_PI);
reg.setCurvatureThreshold(curvature_threshold);

reg.extract(rg_clusters);
\end{lstlisting}

\subsubsection{Convex Hull}

\subsubsection{Polygon Centroid}

\subsection{Ray Tracing Intersection Computation} \label{sec:ray tracing}

\subsubsection{Ray Intersect Sphere}

\subsubsection{Ray Intersect Triangle}

\subsubsection{Ray Intersect Polygon}

Ray intersect with openings.

\subsection{Octree Partitioning}

To accelerate the computation of ray tracing, we use octree to partition the point cloud and mesh

\subsubsection{Point Cloud}

Directly partition point cloud into octree.

\subsubsection{Mesh}

Partition mesh into octree based on center of gravity of each triangle.

\subsection{Other Libraries Serve as Supporting Components} \label{sec:supporting libraries}

\subsubsection{JsonCpp - Parameter Parser} \label{subsec:jsoncpp}

\begin{lstlisting}[language=json, caption=Json Configuration File]
"occlusion": {
	"mesh": {
		"path": "../files/conf_m.obj",
		"pattern": 1,
		"octree_resolution": 128.0,
		"enable_acceleration": true,
		"samples_per_unit_area": 0.001
	},

	"point_cloud": {
		"path": "../files/conf1_80000.pcd",
		"num_rays_per_vp": 10000, 
		"num_vp": 9, 
		"point_radius": 0.025,
		"polygon_path": "../files/polygon_conf.txt",
		"octree_resolution": 0.5
	},

	"rg_mesh": {
		"seg_config": {
			"min_cluster_size": 100,
			"max_cluster_size": 1000000,
			"num_neighbours": 40,
			"k_search_neighbours": 80,
			"smoothness_threshold": 4.0,
			"curvature_threshold": 1.0
		},
		"path": "../files/conf1.pcd",
		"pattern": 0,
		"octree_resolution": 1.0,
		"enable_acceleration": true,
		"samples_per_unit_area": 2
	}
},
\end{lstlisting}

\subsubsection{Websocketpp - Communication Channel} \label{subsec:websocketpp}

%=====================================================================
\subsubsection{OpenMP - Parallel Computation} \label{subsec:openmp}
\begin{lstlisting}[language=C++, caption=Region Growing]
#pragma omp parallel for
for(auto& ray : t_rays) {
	// computing ray triangle intersection
}
\end{lstlisting}
%=====================================================================

%=====================================================================
\subsubsection{Run Backend Server in Command Line} \label{subsec:backend command line}

Start backend server in command line.

\begin{lstlisting}[style=terminal]
	make -j8
	./pcd_pipeline -b
\end{lstlisting}
%=====================================================================

%=====================================================================
\section{Web Based User Interface} \label{sec:three.js}

We present this software in a form of a web application. The pcl based backend serves as a computation engine, while the frontend serves as user interface. We have introduced the main components of the backend in \ref{sec:pcl and eigen}. In this section, we will introduce the frontend and the communication between the frontend and the backend. 

The user interface is shown in Figure \ref{fig:web user interface}. 

\noindent
\begin{minipage}{\textwidth}
	\begin{figure}[H]
		\includegraphics*[width=1.0\textwidth]{figures/ui.png}
		\caption{Web User Interface }
		\label{fig:web user interface}
	\end{figure}
\end{minipage}
%=====================================================================

\subsection{Three.js Serves as Visualization Engine}

Three.js is a cross-browser JavaScript library and application programming interface (API) used to create and display animated 3D computer graphics in a web browser. Three.js uses WebGL.

\subsection{Web Technical Stack}

Since we use three.js as visualization engine, we have to use some web technologies to develop the frontend. The web technical stack we use is as follows: 

\begin{itemize}
	\item \textbf{TypeScript} - A strict syntactical superset of JavaScript and adds optional static typing to the language.
	\item \textbf{TailwindCSS} - A utility-first CSS framework for rapidly building custom user interfaces.
	\item \textbf{Vite} - A build tool that aims to provide a faster and leaner development experience for modern web projects.
	\item \textbf{Websocket} - A computer communications protocol, providing full-duplex communication channels over a single TCP connection.
\end{itemize}

\subsection{User Interface Usage}

In this part we will introduce our user interface and explain how to use it.

\subsubsection{Stats Panel and GUI}

\begin{itemize}
	\item \textbf{Stats Panel} - Show three different metrics of the scene in different color.
		\begin{itemize}
			\item \textbf{Frame Rate} - Blue, frame rate of the visualization.
			\item \textbf{Network Latency} - Green, network latency.
			\item \textbf{Cache Size} - Red, cache size of the point cloud.
		\end{itemize}
	\item \textbf{Light Intensity} - Control the intensity of the light source.
	\item \textbf{Show Cloud} - Show the point cloud.
	\item \textbf{Use Shader Material} - Use shader material to visualize the point cloud.
\end {itemize}	

\subsubsection{Buttons}

\begin{itemize}
	\item \textbf{Original Cloud} - Upload and visualize original point cloud.
	\item \textbf{Segmented Cloud} - Upload and visualize segmented point cloud.
\end{itemize}

\subsection{Software Structure}

\subsubsection{Flowchart}

\begin{minipage}{\textwidth}
	\begin{figure}[H]
		\centering
		\includegraphics*[width=1.0\textwidth]{figures/Minkowski Engine.png}
		\caption{Flowchart of the Software}
		\label{fig:flowchart}
	\end{figure}
\end{minipage}

\subsubsection{Class Diagram}

\begin{minipage}{\textwidth}
	\begin{figure}[H]
		\centering
		\includegraphics*[width=1.0\textwidth]{figures/Minkowski Engine.png}
		\caption{Class Diagram of the Software}
		\label{fig:class diagram}
	\end{figure}
\end{minipage}

\subsubsection{Sequence Diagram}

\begin{minipage}{\textwidth}
    \begin{figure}[H]
        \centering
        \includegraphics*[width=1.0\textwidth]{figures/Minkowski Engine.png}
        \caption{Sequence Diagram of the Software}
        \label{fig:sequence diagram}
    \end{figure}
\end{minipage}

\subsection{Command Line Only Mode}

This project is designated to be used in a web application. However, we also provide a command line only mode for users who want to use this project in a command line environment. In this mode, we use a simple command line interface to interact with the backend.

\subsubsection{Arguments and Corresponding Functionality}

\begin{itemize}
	\item \textbf{-moc} - Mesh Occlusion Computation.
	\item \textbf{-rgoc} - Region Growing Occlusion Computation.
	\item \textbf{-poc} - Point Cloud Occlusion Computation.
\end{itemize}


%=====================================================================
\chapter{Experimental Results} \label{chp:experiments}
%=====================================================================

The evaluation discusses the proposed and competing solutions in the light of the initially stated problem requirements and limitations. This typically involves some sort of experimental evaluation which leads to some type of qualitative or quantitative results.

Quantitative results include observed numbers indicating performance timings (speed) or accuracy measures of the given implementation and test datasets. If possible, statistical tests and analysis should be given, or where applicable formal proofs. Meaningful and informative numerical results must be complete and unambiguous. Explain in detail how the evaluation has been designed, as well as the experimental setup and test cases. This includes accurate description of the test data (type, properties, size etc.) as well as the test setup (e.g. view settings, screen resolution etc.), the values of parameters and the measured variables (frame rate, throughput, accuracy etc.).

Qualitative results may be reported if clear quantitative measures are not feasible or applicable. Qualitative results clearly show the features and functionality of the completed work, indicating if and how they are novel or different from prior work. Qualitative results are especially suitable if something \emph{new} has been achieved that no-one has done before in the same way.

Essentially, the goal of the experimental results is to convince the reader by numbers, tests and images (and maybe user studies), giving some sort of proof why the proposed solution is good, different and/or better than other solutions.

\section{Mesh Based Occlusion Level Validation}

\subsection{Ground Truth Mesh}


\subsection{Estimated Mesh from Point Cloud}

\section{Segmentation Performance Evaluation of Point Cloud}

%=====================================================================
\chapter{Conclusion and Discussion} \label{chp:conclusion}
%=====================================================================

The last section puts the results in perspective, discussing it in relationship to other related work in one or maximum two pages. Indicate possible (side-)effects and eventual limitations due to the evaluation, but try to keep yourself short and clear. Give a short discussion about your results where you focus on what your findings mean. E.g., show how your results and interpretations agree with the original problem question and with other published work or if there are any other practical applications for your work.

State the \emph{take home message} of the paper that the reader should remember and provide an outlook on possible future work that extends the given solution or fixes specific limitations. Close with a brief description (that is different from the Abstract) of the proposed solution.

%-------------------------------------------------------------------------------------------------------------------------
\chapter{Acknowledgements} \label{chp:acknowledgements}

Acknowledge any data and code sources you used or for help you received.


%=====================================================================
\chapter*{Document, Writing and Formatting Guidelines}
%=====================================================================

This part of the document uses non-numbered chapter and section headings as they are not part of a regular report structure. In a regular report, \texttt{chapters}, \texttt{sections} and \texttt{subsections} should normally be numbered. Note the use of comment lines and spacings to give more structure to the ASCII text LaTeX document.

In this appendix like part we discuss the structure and formatting rules and guidelines to follow for a written project, research paper, Bachelor or Master thesis report.

%-------------------------------------------------------------------------------------------------------------------------
\section*{Text} \label{sec:text}
%-------------------------------------------------------------------------------------------------------------------------

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Overall Strategies}

The appearance, clarity and organizational structure of a paper is as important as its technical content, but the technical content must be there beforehand. The presentation alone, however, can make the difference between a mediocre and great publication. Exploit all suitable mechanical rules that can always be applied and optimized independently of the technical part.

The paper has to be convincing even to the adverse reader, i.e. a critical reviewer evaluating your work. Think of being a reviewer yourself, not really knowing your domain and possibly not specifically interested in your work. All information must be crystal clear to a non-expert reader, and all terms and concepts must be properly introduced in a logical order. Put yourself in the position of reading that topic and your work for the very first time, with the goal of having to reproduce it afterwards. The presentation must be flawless and the length of the paper must match the amount of content.

Your report must present your work and solution, best within a convincing story about a difficult problem challenge and an important application domain. The text has to encompass and sell your work. Build up and identify the key challenges in the introduction and problem description. Show clearly how you solved exactly this very important problem in a great and unique novel way.

Group your ideas and concepts hierarchically into sections, subsections and even paragraphs. Strictly introduce general and common ideas, concepts and techniques before expanding further on them. Use the concepts of \emph{repetition} and \emph{parallelism} in your text and structure. The main concept of repetition is to:

\begin{quotation}
Introduce what you are going to tell them -- then tell them in detail -- and finally review what you told them.
\end{quotation}

This approach of repetition is applied on all levels of a report, overall document, sections, subsections and paragraph, always in an appropriate level of abstraction or detail. Example levels:

\begin{description}
\item[Document] The introduction briefly describes the main problem, previews your contribution and summarizes the main results. The main technical sections describe your approach in more detail and the experiments show the achieved results. Finally the conclusion, discussion and future work section(s) summarize your contributions.
\item[Section] In the first paragraph(s) you introduce the topic or aspect that this section covers, followed by the (technical) details, and the last paragraph typically wraps it up, or leads to the next section.
\item[Paragraph] The first sentence of a paragraph leads into the main \emph{message} of this paragraph, and the last sentence concludes it or leads over to the next paragraph.
\end{description}

The concept of parallelism means to apply the same strategy or structuring to different parts. E.g. for each technical problem question or topic covered in one section, first introduce the problem definition and then describe the solution subsequently, possibly in subsections and paragraphs. Or for each type or version of experimental results, or for each data set, describe the data, method parameters, measured variables, report and discuss the results.

It is important to get your text exactly clear to the reader and to avoid the impression that something has been left out or that your contribution is not that significant. But do not over-claim, and more importantly do not under-claim either.

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Writting and Structure}

Writing is difficult work and usually takes more time than expected. It's beneficial to formalize and write down your progress as early as possible. Generally \emph{you cannot really be sure that you know something until you are able to explain it} well in writing. Hence conveying ideas exactly but in a concise and compact manner is very important and a key to successful writing. Preciseness and compactness are key to be able to describe a large amount of work and results that you have.

Your text must be smooth, forming a clear and logical order of your thoughts and arguments. Use \emph{parallelism} to introduce a set of topics, questions or issues and then elaborate on them subsequently in sections and paragraphs.

Use \emph{repetition}, e.g. introduce the problem, show how to solve it and review the benefits. Do not assume that the reader still remembers what was mentioned only as a passing comment three pages back, use repetition and parallelism.

Do not abruptly jump topics but motivate topic changes. If the topics of text parts change too much, then divide them into subsections or paragraphs. If between paragraphs there are major changes (sequence of different concepts etc.), try to use inline paragraph headings for easy navigation and orientation. One way to integrate such paragraph sequences is to write an introductory paragraph at the beginning of the section and use parallelism.

%--------------------------------------------------------
\subsubsection*{Sections and Paragraphs}

Use \texttt{sections}, \texttt{subsections} and \texttt{paragraphs} to structure your ideas and content into meaningful parts, and make a clear and meaningful order of them. Each section, subsection or paragraph must cover a clearly delineated topic or idea.

Every section must first introduce to the reader what to expect and then tell the details, following the principles of repetition and parallelism. An introductory paragraph is also a good approach to fill the space between the section heading and the first sub heading if subsections are used. The last paragraph of a section can summarize the concepts and lead over to the next topic or section.

Each paragraph should have one clear single message, there should only be one consistent topic or idea what the paragraph is about. The first paragraph of a section should clearly lead into the main topic of that section, and the first line of a paragraph should state or at least clearly lead into the main message of that paragraph.

Every single sentence should be fully comprehensible in its context, taking only minimal preliminary knowledge of previous paragraphs into account.

%--------------------------------------------------------
\subsubsection*{Wording and Postprocessing}

Use single tenses (i.e. the present or present perfect) as much as possible when describing your design, technical or algorithmic solutions. Generally use present perfect for describing implementations and results which were completed, as this implies something that happened as part of this work in the past but continues to be valid in the present as a result of this paper.

"I" versus "we": For a personal opinion, or your specific personal contribution, you can use the first person. In a personal thesis report one can use "I" as this one's own contribution and text.

For most situations a neutral form should be used, passive voice or third person, but be careful to avoid the interpretation of "passive voice" as "someone else did it, and it is not our contribution", e.g. "This mind-boggling observation was made." vs. "We made this mind-boggling observation.".

Read through the text, spell check, and check the text with a grammar tool as well. Obvious errors are unacceptable.
Try to take the role of a reviewer or evaluator: Reading your paper or report costs that person significant time, so question everything. The reviewer may not be forgiving if something is not clear. Be the devil's advocate!

Do not use abbreviations (don't -> do not).

%-------------------------------------------------------------------------------------------------------------------------
\section*{Formatting and Typesetting} \label{sec:formatting}
%-------------------------------------------------------------------------------------------------------------------------

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{General Rules}

The main text area should have a margin of about 2cm on both sides, and the main text should have a top and bottom margin of about 3cm each.

Section and subsection headings have nested numbering and are typeset in sans-serif bold font type, e.g. Helvetica or Arial.  Sizes range from 18pt for main sections down to at least one point larger than the main body text size. Some vertical space before and after section headings is placed (automatically according to the LaTeX document class of this template).

The main body text is typeset in 11pt Times font (serif font family). Text body is one-column, justified and single-spaced. First line of a paragraph is generally indented with about 0.8cm, however, first paragraph after any section heading may also be non-indented.

\begin{itemize}
\item Avoid extensive and manual spacing
\item Use font modifications carefully
%\item Use the \verb!\emph{}! command fo emphasizing/italicizing not \verb!\textit()!
\item Use proper math and symbol styles
%\item Use (our math.tex) style file for consistency
\end{itemize}

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Folder Structure}

Use main folder for the main latex .tex and .bib files, the main paper body and bibliography database. Optional: use a folder, e.g. ./sections, to separately manage individual section's latex files.

Use ./images and ./figures subdirectories for the raster images and vector graphics used in the figures and diagrams of the paper.
Only use .jpg and .pdf formats respectively for best results. Put source files, e.g. from Illustrator or OmniGraffle, also directly into the ./figures folder along with the PDF versions.

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Latex Coding}

Follow a clear prologue structure in the LaTeX source file. After the given template components add your \verb!\usepackage{}! block, and \verb!\input{math}! to include our standard math formula definitions. Complete the preamble by any further specific definitions or commands, e.g. \verb!\TODO! and \verb!\FIXME! macros. After the prologue, complete the title and author parts.

If separate .tex files are used for the main report text body, then include them in the main body latex file, and in each of these files indicate the root latex file at the very top:
\begin{verbatim}
%\!TEX root = ../<main_file_name>.tex!
\end{verbatim}

\noindent
Further LaTeX coding guidelines and recommendations:

\begin{itemize}
\item Use the \verb!\emph{}! command fo emphasizing/italicizing not \verb!\textit()!
\item Use (our math.tex) style file for math formula consistency
\item Use \verb!\mathrm{function()}!  for function names
\item Use consistent section, equation and figure labelling
\verb!\label{sec:introduction}! as well as \texttt{eq:rendering, fig:system}
\item Do not liberally introduce manual horizontal or vertical spacings
\item In particular do not use comment codes \% to control spacing or indentation before or after elements, e.g. arounc equations, figures or tables
\end{itemize}

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Mathematical Formulas and Equations}

Mathematical expressions should follow a consistent set of rules, symbols and formatting as indicated in our \texttt{math.tex} style file. LaTeXiT can be used for consistent symbols and formulas in figures. Apply the same scalar, vector and matrix styles as well as use the same variables consistently throughout your text, see also the predefined styles and specific variables in \texttt{math.tex}. A few guidelines that are useful are given below, use them as much as possible (but adjust as necessary to make formulas clear):

\begin{itemize}
\item use (lower-case) italic letters for normal (scalar) variables such as $x$ or $t$
\item prefer $i$ and $j$ as index variables and $m$ and $n$ to denote number of elements or iterations
\item use for example other letters such as $a$, $b$ and $c$ for constants
\item use lower-case bold italic to denote vectors such as $\vec{u}$ or $\vec{v}$
\item use upper-case bold letters such as $\mat{M}$ or $\mat{N}$ for sets and matrices
\item use upper- or lower-case italic letters such as $f()$ or $G()$ to denote functions
\item use regular plain font and decimal point to denote explicit constants such as $2$ or $100.12$
\end{itemize}

Use as much formalism, variables and equations, as is useful to clearly understand your description, but not for trivial facts. Use inline equation format also for variables like $x$ and numbers like $12$ used in the main text body segments.

Mathematical equations that are important or are referenced should be laid out as a  regular equation with consecutive numbering to the right as below:

%% example equation  %%
\begin{equation}
E = m \cdot c^2
\label{eq:einstein}
\end{equation}

Such regular free standing equations do not need a punctuation and follow a paragraph that ends with a dot or double-colon, and the following paragraph starts regularly indented.

Equations may also be treated 'inline' with the main flow of the text, thus being part of one regular sentence. Such 'inline' equations as
%
\begin{equation*}
a^2 + b^2 =  c^2,
\end{equation*}
%
typically end with a comma and the text continues below unindented lower-case to finish the sentence. To adjust spacing, the equation can be connected to the paragraph text flow by separating it only using \% comments. If an equation ends the sentence of a paragraph it ends with a dot.


%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Floats, Figures, Screenshots and Graphs}

Figures, screenshots, tables, graphs and other floats should support the overall idea of the paper or some description in the text specifically, and are numbered sequentially. Every figure must support a key idea or concept, and it must be meaningful with self-explanatory captions.

\begin{quotation}
Make sure every figure or float is placed correctly and is used as well as referenced in the text.
\end{quotation}

\paragraph{Placement}
Each float is centered and \emph{placed in the text directly after} the first paragraph referencing it, never directly after a heading. If formatting constraints are difficult, figure placement may be forced, e.g. to be placed at the top of the next possible new page.
In double-column document formats, put large floats spreading both columns at the top of the next following page.

\paragraph{Figures}
Use a consistent style and appearance for each figure, using clean lines and diagrams. Make careful use of not too bright or disturbing colors, and watch out for grayscale usage when printed.

Use sans-serif fonts in figures and diagrams unless for math symbols and variables. Enforce consistent upper-lower case usage throughout all figures and terms used in the text, and match variables and math formulas or symbols in figures to the ones in in the text. Also match the size of text in figures to the size of the main paper body text.

For figures and diagrams that include any vector graphics elements (e.g. arrows, lines, boxes, points etc.), use the PDF vector graphics format with white or transparent background, and do not use raster image formats. If raster images are included in vector graphics figures, also use the PDF format for the combined figure.

\paragraph{Screenshots}
Each screenshot must demonstrate a clear visual effect, or major point of your work, or an example or problem of a standard (prior) approach. Some, very few, images may be mostly visual teasers. Each screenshot must include all details such as (data) statistics, used parameters and experimental settings in the caption or in the accompanying text where the figure is referenced from. Use raster image formats only for image-only figures, and then use the JPG file format not PNGs.

\paragraph{Graphs}
Graphs and plots must clearly demonstrate some numerical test results or data statistics. Strictly avoid clutter within one graph, and clearly relate parameters and results of experiments. Just listing basic values can be done in simple tables.
Use expressive and clearly labelled axis in all graph plots. Graphs should basically be understandable on their own along with their caption also without reading the main text. Graphs and plots are usually based on vector graphics, thus use the PDF vector graphics format with white or transparent background as for figures and diagrams.

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Cross-References}

Cross-references to numbered items such as sections and figures are capitalized as in the following examples. In Section~\ref{chp:introduction} we provide a brief summary of text formatting instruction and Figure~\ref{fig:logo} shows our group logo. A figure can contain multiple subfigures which can be referenced individually as illustrated in Figure~\ref{fig:uzh}.

%% example figures %%
\begin{figure}[htp]
 \centering
 \includegraphics[width=0.5\textwidth]{figures/vmml_logo}
 \caption{Example of single figure with caption text.}
 \label{fig:logo}
\end{figure}

\begin{figure}[htp]
 \centering
\subfigure[vmml logo]{\includegraphics[width=0.3\textwidth]{figures/vmml_logo} \label{fig:vmml}} \hfill
\subfigure[uzh logo]{\includegraphics[width=0.3\textwidth]{figures/uzh_logo} \label{fig:uzh}}
 \caption{Example subfigure with captions referencing (a) the VMML and (b) the UZH logos.}
\end{figure}

Use the same full or shortened form for all references, e.g. Sec.~\ref{chp:introduction}, Fig.~\ref{fig:vmml}, Eq.~\ref{eq:einstein}.

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Pseudo Code}

Example for a pseudo code given below

%% example pseudo code %%
\lstinputlisting[language=c++,label=example]{pseudocode/example_pcode.txt}
\vspace{10mm}

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Commands}

You can use the command \verb!\FIXME{}! in order to mark sections in the text, which need to be edited and fixed. E.g. \FIXME{check reference XY}.


%-------------------------------------------------------------------------------------------------------------------------
\section*{Bibliography}
%-------------------------------------------------------------------------------------------------------------------------

The bibliography with list of references is placed on a new page at the end of the document, titled ``References'' or ``Bibliography'' and typeset similar to the main section headings but without numbering. Bibliography entries should follow standard IEEE or ACM proceedings or transaction journal formatting styles, and be referenced by last name abbreviation and year such as e.g. \cite{Pajarola:07} and \cite{GSSP:10}, or by number as for [1].

%-------------------------------------------------------------------------------------------------------------------------
\subsection*{Formatting References}


Bibliography entries should be clean, accurate, compact and consistent across all entries. Thus for the entries in the BibTeX bibliography .bib file follow the following basic rules:

\begin{itemize}
\item Have complete entries, including full author names (first and last), full conference paper (inproceedings type with name, year, pages) and journal (article type with journal name, volume, number/issue, month) data
\item Use capitalized title and special terms, e.g. "Point Set Processing for Data Analysis on the {GPU}".
\item Use consistent venue description (name the same conference/journal in the same way).
\item Use compact \emph{inproceedings} booktitle for conferences without year, i.e. "Proceedings IEEE Visualization" instead of "8th Int. Conference on Visualization (VIS'08), IEEE 2008".
\item Do not use separate organization field if clear from the conference or journal, and usually no publisher, month and address for conferences.
\item Keep entries concise, avoid unnecessary or duplicate information such as e.g. address or location for conferences or even journals, redundant numpages fields, or duplicated association/organization data etc.
\item Use these fields sparsely if at all necessary: howpublished, publisher (don't for conferences, only for books or so), series (don't for conferences, only for LNCS or similar)
\item Typically do not use venue, address or location for conferences or even journals
\item Keep keywords simple and meaningful (e.g. main first keyword graphics, visualization, geometry, theory, databases, mathematics etc. followed by a few more specific ones)
\end{itemize}

\noindent
Example bad BibTeX entry:

\begin{verbatim}
@ inproceedings{as78439729asf,
  Title = {Tile-based LOD for the Parallel Age},
  Author = {Niski, Krzysztof and Cohen, J.~D.},
  Booktitle = {Proceedings IEEE Visualization Conference (IEEE Vis'10)},
  Volume = {13},
  Pages = {1352},
  Organization = {IEEE},
  Series = {IEEE TVCG journal},
  Publisher = {Computer Society Press},
}
\end{verbatim}

\noindent
Above BibTeX entry will result in a not very nice, incomplete and inconsistent reference:

\smallskip
\noindent
[NC] Krzysztof Niski and J. D. Cohen. Tile-based lod for the parallel age. In \emph{Proceedings IEEE Visualization Conference (IEEE Vis'10)}, volume 13 of \emph{IEEE TVCG journal}, page 1352. IEEE, Computer Society Press.

\bigskip
\noindent
The corresponding clean and consistent BibTeX entry would be:

\begin{verbatim}
@article{NC:07,
  Title = {Tile-based {LOD} for the Parallel Age},
  Author = {Niski, Krzysztof and Cohen, Jonathan~D.},
  Journal = {IEEE Transactions on Visualization and Computer Graphics},
  Month = {November/December},
  Volume = {13},
  Number = {6},
  Pages = {1352--1359},
  Year = {2007}
}
\end{verbatim}

\noindent
This will result in a nice and consistent reference:

\smallskip
\noindent
[NC07]  Krzysztof Niski and Jonathan D. Cohen. Tile-based LOD for the parallel age. \emph{IEEE Transactions on Visualization and Computer Graphics}, 13(6):1352-1359, November/December 2007.

\vspace{5mm}
More bad examples include the following
\begin{quotation}
\cite{HWH:10bad,Suss:10bad,HXS:09bad,CH:09bad,Strugar:10bad,Fout:07bad,WGS:07bad,CMF:05bad,AGLMR:02bad,Koltun:00bad,CYHPK:97bad}, 
\end{quotation}

and the good ones are these here
\begin{quotation}
\cite{HWH:10,SWF:10,HXS:09,CH:09,Strugar:10,FM:07,WGS:07,CMF:05,AGLMR:02,KCC:00,CYHPK:97}.
\end{quotation}


%=====================================================================
\chapter*{Pages}
%=====================================================================


%-------------------------------------------------------------------------------------------------------------------------
\section*{Cover and Abstract}
%-------------------------------------------------------------------------------------------------------------------------

Title of thesis, author, affiliation, date and any other administrative information should be placed on a separate cover page (see first page).

Main title of work should be typeset in large sans-serif bold font type. Title is to be followed by author and affiliation. At the bottom, separated group affiliation is set.

Abstract follows on separate page after cover page and before the table-of-content page(s).


%-------------------------------------------------------------------------------------------------------------------------
\section*{TOC}
%-------------------------------------------------------------------------------------------------------------------------

The table-of-content (TOC) contains all Section and (Sub-)Sub Section headings and their corresponding pages and is listed on separate pages before the first section. It has its own heading typeset as a section heading without numbering.

%%=====================================================================
%\chapter{Conclusion} \label{chp:conclusion}
%%=====================================================================
%
%Summarize your main findings in one or maximum two pages. Try to keep yourself short and clear. Give a short discussion about your results where you focus on what your findings mean. E.g., show how your results and interpretations agree with the original question and with other published work  or if there are any possible practical applications for your work. At the end, give hints on further improvements or development directions / areas. 

\bibliographystyle{alpha}
\bibliography{references,bad_refs,corrected_refs}
\end{document}
